{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d1a1a6-a3da-48e4-9872-9907f453bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###DATASET CONSTRUCTION\n",
    "import torch\n",
    "import scipy \n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "##SNET DATA PATH\n",
    "X = scipy.io.loadmat('C:\\\\Users\\\\Gurur\\\\capa_snet_destrieux_normalizedweighted.mat')\n",
    "X = X[\"capa_snet_destrieux_normalizedweighted\"]\n",
    "\n",
    "index = np.hstack(  (np.where( X[:,1]==\"MCI\" ) ,np.where( X[:,1]==\"Erken AD\" )) ).T\n",
    "X=np.squeeze(X[index,:])\n",
    "\n",
    "\n",
    "def convert_to_tensor(data,d_type=None):\n",
    "    data = np.asarray(data,dtype=np.float32)\n",
    "    data = torch.from_numpy(data)\n",
    "    if d_type==\"long\" :\n",
    "        data = data.long()\n",
    "    return data\n",
    "\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for i in range(0, X.shape[0]):\n",
    "    item = X[i,0]\n",
    "    edge_index = convert_to_tensor(np.nonzero(item),d_type=\"long\")\n",
    "    label = X[i,1]\n",
    "    #SOURCE 0: TARGET 1\n",
    "    new_index= torch.zeros([2,edge_index.size()[1]],dtype=torch.long)\n",
    "    new_index[0] = edge_index[1]\n",
    "    new_index[1] = edge_index[0]\n",
    "    \n",
    "    item[item > 0] = 1\n",
    "    x = convert_to_tensor(item + np.identity(148))\n",
    "    if   label==\"Erken AD\":\n",
    "        y = torch.tensor([1], dtype=torch.long)\n",
    "    else :\n",
    "        y = torch.tensor([0], dtype=torch.long)\n",
    "    data = Data(x=x, edge_index=new_index, y=y)\n",
    "    dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0470a7d3-338f-43b5-b6b4-a0da3ee218c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD SAVED CROSS VALIDATION INDEXES FOR FAIR COMPARISON OF MODELS\n",
    "load = True\n",
    "if load == False :\n",
    "    fold_num = 8\n",
    "    fold_arr = np.arange(len(dataset))\n",
    "    np.random.shuffle(fold_arr)\n",
    "    fold_arr = np.split(fold_arr, fold_num)\n",
    "else :\n",
    "    fold_num = 8\n",
    "    fold_arr = np.load(\"8fold_v1.npz\")[\"arr_0\"]\n",
    "\n",
    "y = []\n",
    "for i in range(len(dataset)):\n",
    "    y.append(dataset[i].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54dfe2e-67b8-47af-b681-97f961bac353",
   "metadata": {},
   "outputs": [],
   "source": [
    "###ATTENTION BASED GRAPH POOLING LAYER\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.utils import softmax\n",
    "from typing import Optional\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn.aggr import Aggregation\n",
    "\n",
    "class AttentionalAggregation(Aggregation):\n",
    "\n",
    "    def __init__(self, gate_nn: torch.nn.Module,\n",
    "                 nn: Optional[torch.nn.Module] = None):\n",
    "        super().__init__()\n",
    "        self.gate_nn = gate_nn\n",
    "        self.nn = nn\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        reset(self.gate_nn)\n",
    "        reset(self.nn)\n",
    "\n",
    "    def forward(self, x: Tensor, index: Optional[Tensor] = None,\n",
    "                ptr: Optional[Tensor] = None, dim_size: Optional[int] = None,\n",
    "                dim: int = -2) -> Tensor:\n",
    "\n",
    "        self.assert_two_dimensional_input(x, dim)\n",
    "        gate = self.gate_nn(x)\n",
    "        x = self.nn(x) if self.nn is not None else x\n",
    "        gate = softmax(gate, index, ptr, dim_size, dim)\n",
    "        return self.reduce(gate * x, index, ptr, dim_size, dim), gate\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(gate_nn={self.gate_nn}, '\n",
    "                f'nn={self.nn})')    \n",
    "\n",
    "class GlobalAttention(AttentionalAggregation):\n",
    "    def __call__(self, x, batch=None, size=None):\n",
    "        return super().__call__(x, batch, dim_size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b64428a-4b3e-4984-bdb3-8b723b73fd35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###DAGNN\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import  global_add_pool, global_mean_pool, global_max_pool, Set2Set, GINConv,GATConv,GCNConv,TransformerConv\n",
    "import math\n",
    "from torch_geometric.utils import to_dense_batch, to_dense_adj\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def f1_calculation(y,patient_results):\n",
    "    y_pred = np.zeros(len(y))\n",
    "    for i,label in enumerate(patient_results) :\n",
    "        if label == 1 :\n",
    "            y_pred[i]=y[i]\n",
    "        else :\n",
    "            y_pred[i] = 1-y[i]\n",
    "    return f1_score(y,y_pred)\n",
    "\n",
    "\n",
    "class DAGNN(torch.nn.Module):\n",
    "    def __init__(self, num_heads):\n",
    "        super(DAGNN, self).__init__()\n",
    "\n",
    "        num_features = 148\n",
    "        dim1 = 128\n",
    "        dim_att = 32\n",
    "        dim = dim_att*num_heads\n",
    "        self.heads = num_heads\n",
    "        self.nn1 = Sequential(Linear(num_features, dim1), ReLU(), Linear(dim1, dim1))         \n",
    "        self.conv2 = GATConv(dim1, dim_att , heads = num_heads)            \n",
    "        self.fc1 = Linear(dim, 2)\n",
    "        \n",
    "    def forward(self, inx, edge_index, batch):\n",
    "        x = F.relu(self.nn1(inx))\n",
    "        x, (ind, weight) = self.conv2(x, edge_index, return_attention_weights=True) \n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc1(x)        \n",
    "        return F.log_softmax(x, dim=-1), ind, weight\n",
    "    \n",
    "\n",
    "def disentanglement_loss(ind, weight, batch) :\n",
    "    c = to_dense_adj(ind, batch, weight)\n",
    "    B,N,_,M = c.shape\n",
    "    columns = c.permute(0, 1, 3, 2)\n",
    "    dists = torch.cdist(columns, columns, p=1)\n",
    "    avg_dists = torch.mean(dists, 1)    \n",
    "    return (2*torch.triu(avg_dists, diagonal=1).sum(dim=(1, 2)) /(M*(M-1))).mean()\n",
    "\n",
    "    \n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    ce_loss_all = 0\n",
    "    l1_loss_all = 0\n",
    "    loss_all = 0\n",
    "    for data in data_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, ind, weight = model(data.x, data.edge_index,  data.batch)\n",
    "        ce_loss = F.nll_loss(output, data.y, weight=torch.cuda.FloatTensor([1,1]))\n",
    "        l1_loss = F.relu(2 - disentanglement_loss(ind, weight, data.batch))\n",
    "        loss = ce_loss + 0.1 * l1_loss\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        ce_loss_all += ce_loss.item() * data.num_graphs\n",
    "        l1_loss_all += l1_loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return ce_loss_all / len(dataset), l1_loss_all / len(dataset), loss_all / len(dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output,_,_ = model(data.x, data.edge_index,  data.batch)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct_results = pred.eq(data.y).detach().cpu().numpy()\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    return correct, torch.exp(output)[:,1], correct_results \n",
    "\n",
    "batch_size = 6\n",
    "num_heads = 4\n",
    "test_num = 1\n",
    "epoch_num = 100\n",
    "results = np.zeros([test_num])\n",
    "f1_arr = np.zeros([test_num])\n",
    "patient_results = np.zeros([len(dataset),test_num])\n",
    "patient_scores = np.zeros([len(dataset),test_num])\n",
    "auc_arr = np.zeros([test_num])\n",
    "\n",
    "\n",
    "for t in range(0,test_num):\n",
    "    acc = 0\n",
    "    for i, fold in enumerate(fold_arr) :\n",
    "        print(i)\n",
    "        train_indices = np.delete(np.arange(len(dataset)),fold).tolist() \n",
    "        test_indices = fold\n",
    "        dataset_train =  torch.utils.data.Subset(dataset, train_indices)\n",
    "        dataset_test = torch.utils.data.Subset(dataset, test_indices)       \n",
    "        data_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "        data_loader_test = DataLoader(dataset_test, batch_size=len(fold))\n",
    "\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        model = DAGNN(num_heads).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "        for epoch in range(1, epoch_num+1):\n",
    "            train_loss = train(epoch)\n",
    "            train_acc,_,_ = test(data_loader)\n",
    "            train_acc = train_acc/(len(train_indices))\n",
    "            test_acc,logits,test_results = test(data_loader_test)\n",
    "            #print('Epoch: {:03d}, Train Loss: {:.7f}, '\n",
    "                  #'Train Acc: {:.7f}'.format(epoch, train_loss,train_acc))\n",
    "        patient_scores[fold, t] = logits.detach().cpu().numpy()                 \n",
    "        patient_results[fold,t] = test_results \n",
    "        acc = acc + test_acc\n",
    "        del model \n",
    "    f1_arr[t] = f1_calculation(torch.cat(y),  patient_results[:,t])\n",
    "    auc_arr[t] = roc_auc_score(torch.cat(y),  patient_scores[:,t])\n",
    "    acc = acc/len(dataset) \n",
    "    print(acc)\n",
    "    results[t] = acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
